代码倒挺简单的，总体来说就是neuronal_charge和neuronal_reset的过程中加了detach，切断了相应的反向传播通道

neuron dropout的时候好像self.mask没动过？——是动了的，forward函数里有调用

spiking_vgg.py里的replace和WrapedSNNOp是啥？
OnlineSpikingVGGF里的self.fb_conv那条线融合了上一个iter过完主干网络之后的feature，暂时不知道有啥用
WrapedSNNOp的反向传播：output -> out_for_grad -> in_for_grad -> rate -> spike。相当于rate替换掉spike进行反向传播——
这里的rate在neuron.py的OnlineLIFNode中产生，对应论文中的pL/pW的公式。

OTTT的实现方式应该还是和论文里不一致的。

charge -> fire -> reset，charge是自己的，fire和reset都是继承spikingjelly的


python train_dvsgesture.py -data_dir ../../datasets/dvs128_gesture/ -out_dir logs/dvsgesture -gpu-id 5

python train_cifar.py -data_dir ../../datasets/cifar100/ -dataset cifar100 -weight_decay 0.0005 -out_dir logs/cifar100_WD -gpu-id 1

python train_cifar.py -data_dir ../../datasets/cifar100/ -dataset cifar100 -BPTT -out_dir logs/cifar100_BPTT_BN -BN -gpu-id 5
python train_cifar.py -data_dir ../../datasets/cifar100/ -dataset cifar100 -BPTT -out_dir logs/cifar100_BPTT_WS -WS -gpu-id 6
python train_cifar.py -data_dir ../../datasets/cifar100/ -dataset cifar100 -BPTT -out_dir logs/cifar100_BPTT_BN_WS_WD -BN -WS -weight_decay 0.0005 -lr 0.05 -gpu-id 7
